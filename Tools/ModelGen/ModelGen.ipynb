{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b224dd2",
   "metadata": {},
   "source": [
    "# ModelGen: PyTorch â†’ LTspice Model Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255334b",
   "metadata": {},
   "source": [
    "This notebook is a utility tool for generating PyTorch models from simple switch-based definitions,\n",
    "automatically converting them into standalone `.py` classes and LTspice subcircuits `.sp`, and then \n",
    "running parity checks between PyTorch and LTspice outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "\n",
    "1. **Switch-based model definition**  \n",
    "   - Models are defined with `nn.Sequential` presets using a simple `make_model()` function.  \n",
    "   - Users only need to add a new `elif` block to register their own model.  \n",
    "   - Supports:\n",
    "     - Pure MLP (no recurrent cells)  \n",
    "     - Models with `RNNCell`, `GRUCell`, `LSTMCell` at any layer  \n",
    "     - Stacked recurrent cells  \n",
    "\n",
    "2. **Automatic code generation**  \n",
    "   - From a given `nn.Sequential`, the notebook generates a PyTorch class (`<NAME>`) with:\n",
    "     - `step(x, state)` for stateful execution  \n",
    "     - `forward(x)` for stateless execution  \n",
    "   - The code is saved as a `.py` file in the same directory.\n",
    "\n",
    "3. **LTspice subcircuit export**  \n",
    "   - The generated model class (not the original `Sequential`) is exported to a `.sp` file.  \n",
    "   - Input/output ports: `NNIN1..NNIN9`, `NNOUT1..NNOUT2`.  \n",
    "   - Hidden ports (`HIN*`, `HOUT*`, `CIN*`, `COUT*`) are included automatically if recurrent cells exist.  \n",
    "   - The `.py` and `.sp` files are always created as a **pair**.\n",
    "\n",
    "4. **Parity check utilities**  \n",
    "   - LTspice is run with a selected `.asc` environment (e.g., `env_buck_9x2.asc`).  \n",
    "   - Observations from LTspice are passed to the PyTorch model.  \n",
    "   - PyTorch outputs are compared with LTspice outputs (`NNOUT*`).  \n",
    "   - MAE/MSE metrics can be printed and plotted.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20ace2",
   "metadata": {},
   "source": [
    "## Change Log:\n",
    "\n",
    "2025-09-21, Initial Version\n",
    "\n",
    "2025-10-01,\n",
    "- Python Code Generator: added `clone_state` method in generated classes for safe hidden state duplication.\n",
    "- Python Code Generator: updated `forward` in generated classes to accept h as an alias for state.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import importlib.util\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from PyLTSpice import LTspice, RawRead, SimRunner\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', '..', 'PyTorch2LTspice'))\n",
    "from PyTorch2LTspice import export_model_to_ltspice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602efcf5",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb302a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment configuration\n",
    "ENV_NAME = \"env_buck_9x2\"              # Select environment file here\n",
    "ENV_CONFIG = {\n",
    "    \"env_buck_9x1\":  {\"in\": 9, \"out\": 1},\n",
    "    \"env_buck_9x2\":  {\"in\": 9, \"out\": 2},\n",
    "    # Add more environments as needed\n",
    "}\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"mlp\"                     # \"mlp\"/\"rnn_linear\"/\"gru_linear\"/\"linear_lstm_linear\"\n",
    "MODEL_CONFIG = {\n",
    "    \"mlp\":  {\"clk_needed\": False},\n",
    "    \"rnn_linear\":  {\"clk_needed\": True},\n",
    "    \"gru_linear\":  {\"clk_needed\": True},\n",
    "    \"linear_lstm_linear\":  {\"clk_needed\": True},\n",
    "    # Add more models as needed\n",
    "}\n",
    "SUBCKT_NAME = MODEL_NAME                      # Sub-circuit name in LTspice\n",
    "\n",
    "\n",
    "# LTspice simulation configuration\n",
    "SIM_STEP = 200                         # Nnumber of time steps to run in LTSpice \n",
    "SIM_TIMEOUT = 300                      # Timeout therhold in seconds\n",
    "\n",
    "# Working directory for pyLTspice\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ENVDIR  = NOTEBOOK_DIR / \"env\"\n",
    "OUTDIR  = NOTEBOOK_DIR / \"env\"         # save at same directory as .asc file\n",
    "WORKDIR = NOTEBOOK_DIR / \"tmp\" \n",
    "WORKDIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24be7c",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430133c-fcaa-403f-bfee-b36c55ad8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_name: str) -> nn.Sequential:\n",
    "    if model_name == \"mlp\":\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(ENV_CONFIG[ENV_NAME][\"in\"], 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, ENV_CONFIG[ENV_NAME][\"out\"]),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    elif model_name == \"rnn_linear\":\n",
    "        return nn.Sequential(\n",
    "            nn.RNNCell(ENV_CONFIG[ENV_NAME][\"in\"], 32),\n",
    "            nn.Linear(32, ENV_CONFIG[ENV_NAME][\"out\"]),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    elif model_name == \"gru_linear\":\n",
    "        return nn.Sequential(\n",
    "            nn.GRUCell(ENV_CONFIG[ENV_NAME][\"in\"], 32),\n",
    "            nn.Linear(32, ENV_CONFIG[ENV_NAME][\"out\"]),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    elif model_name == \"linear_lstm_linear\":\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(ENV_CONFIG[ENV_NAME][\"in\"], 32),\n",
    "            nn.Tanh(),\n",
    "            nn.LSTMCell(32, 32),\n",
    "            nn.Linear(32, ENV_CONFIG[ENV_NAME][\"out\"]),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    # Example extension for stacked LSTM cells:\n",
    "    # elif model_name == \"stacked_lstm\":\n",
    "    #     return nn.Sequential(\n",
    "    #         nn.LSTMCell(ENV_CONFIG[ENV_NAME][\"in\"], 32),\n",
    "    #         nn.LSTMCell(32, 32),\n",
    "    #         nn.Linear(32, ENV_CONFIG[ENV_NAME][\"out\"]),\n",
    "    #         nn.Tanh(),\n",
    "    #     )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model preset: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dcadc1",
   "metadata": {},
   "source": [
    "---\n",
    "## PyTorch Code Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_LAYERS: Dict[type, str] = {\n",
    "    nn.Linear: \"nn.Linear\",\n",
    "    nn.ReLU: \"nn.ReLU\",\n",
    "    nn.Sigmoid: \"nn.Sigmoid\",\n",
    "    nn.Tanh: \"nn.Tanh\",\n",
    "    nn.RNNCell: \"nn.RNNCell\",\n",
    "    nn.GRUCell: \"nn.GRUCell\",\n",
    "    nn.LSTMCell: \"nn.LSTMCell\",\n",
    "}\n",
    "CELL_TYPES = (nn.RNNCell, nn.GRUCell, nn.LSTMCell)\n",
    "\n",
    "\n",
    "def _layer_to_ctor_line(layer: nn.Module, idx: int) -> str:\n",
    "    prefix = f\"self.l{idx} = \"\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        bias_flag = layer.bias is not None\n",
    "        return f\"{prefix}nn.Linear({layer.in_features}, {layer.out_features}, bias={bias_flag})\"\n",
    "    if isinstance(layer, nn.ReLU):\n",
    "        return f\"{prefix}nn.ReLU(inplace={layer.inplace})\"\n",
    "    if isinstance(layer, nn.Sigmoid):\n",
    "        return f\"{prefix}nn.Sigmoid()\"\n",
    "    if isinstance(layer, nn.Tanh):\n",
    "        return f\"{prefix}nn.Tanh()\"\n",
    "    if isinstance(layer, nn.RNNCell):\n",
    "        bias_flag = bool(layer.bias)\n",
    "        return (\n",
    "            f\"{prefix}nn.RNNCell({layer.input_size}, {layer.hidden_size}, \"\n",
    "            f\"nonlinearity={repr(layer.nonlinearity)}, bias={bias_flag})\"\n",
    "        )\n",
    "    if isinstance(layer, nn.GRUCell):\n",
    "        bias_flag = bool(layer.bias)\n",
    "        return f\"{prefix}nn.GRUCell({layer.input_size}, {layer.hidden_size}, bias={bias_flag})\"\n",
    "    if isinstance(layer, nn.LSTMCell):\n",
    "        bias_flag = bool(layer.bias)\n",
    "        return f\"{prefix}nn.LSTMCell({layer.input_size}, {layer.hidden_size}, bias={bias_flag})\"\n",
    "    raise ValueError(f\"Unsupported layer for code generation: {type(layer)}\")\n",
    "\n",
    "\n",
    "def generate_model_code_from_sequential(name: str, seq: nn.Sequential) -> Tuple[str, str]:\n",
    "    class_name = f\"{name}\".replace('-', '_')\n",
    "    ctor_lines: List[str] = []\n",
    "    model_lines: List[str] = [\"                self.model = nn.Sequential(\"]\n",
    "    cell_indices: List[int] = []\n",
    "\n",
    "    for idx, layer in enumerate(seq):\n",
    "        if type(layer) not in SUPPORTED_LAYERS:\n",
    "            raise TypeError(f\"Layer type {type(layer)} is not supported.\")\n",
    "        ctor_lines.append(f\"                {_layer_to_ctor_line(layer, idx)}\")\n",
    "        suffix = ',' if idx < len(seq) - 1 else ''\n",
    "        model_lines.append(f\"                    self.l{idx}{suffix}\")\n",
    "        if isinstance(layer, CELL_TYPES):\n",
    "            cell_indices.append(idx)\n",
    "\n",
    "    model_lines.append(\"                )\")\n",
    "    ctor_block = \"\\n\".join(ctor_lines)\n",
    "    model_block = \"\\n\".join(model_lines)\n",
    "    cell_idx_literal = ', '.join(str(i) for i in cell_indices)\n",
    "\n",
    "    code = textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        from typing import Any, List, Optional, Tuple\n",
    "\n",
    "        class {class_name}(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "{ctor_block}\n",
    "{model_block}\n",
    "                self._cells = [{cell_idx_literal}]\n",
    "                self._num_layers = {len(seq)}\n",
    "\n",
    "            def _prepare_state_list(self, state: Optional[List[Any]]) -> List[Any]:\n",
    "                if not self._cells:\n",
    "                    return []\n",
    "                if state is None:\n",
    "                    return [None] * len(self._cells)\n",
    "                state_list = list(state)\n",
    "                if len(state_list) != len(self._cells):\n",
    "                    raise ValueError(f\"Expected {{len(self._cells)}} state entries, got {{len(state_list)}}.\")\n",
    "                return state_list\n",
    "\n",
    "            def clone_state(self, state: Optional[List[Any]]):\n",
    "                if state is None:\n",
    "                    return None\n",
    "                def _clone(item):\n",
    "                    if item is None:\n",
    "                        return None\n",
    "                    if isinstance(item, torch.Tensor):\n",
    "                        return item.detach().clone()\n",
    "                    if isinstance(item, (list, tuple)):\n",
    "                        cloned = [_clone(x) for x in item]\n",
    "                        return type(item)(cloned)\n",
    "                    raise TypeError(f\"Unsupported state element type: {{type(item)}}\")\n",
    "                return _clone(state)\n",
    "\n",
    "            def step(self, x: torch.Tensor, state: Optional[List[Any]]):\n",
    "                if x.dim() != 2:\n",
    "                    raise ValueError(\"step expects a 2D tensor shaped (B, D).\")\n",
    "                current = x\n",
    "                state_list = self._prepare_state_list(state)\n",
    "                next_states: List[Any] = []\n",
    "                cell_ptr = 0\n",
    "                for layer_idx in range(self._num_layers):\n",
    "                    layer = getattr(self, f\"l{{layer_idx}}\")\n",
    "                    if layer_idx in self._cells:\n",
    "                        prev = state_list[cell_ptr]\n",
    "                        if isinstance(layer, nn.LSTMCell):\n",
    "                            if prev is None:\n",
    "                                h_prev = current.new_zeros((current.size(0), layer.hidden_size))\n",
    "                                c_prev = current.new_zeros((current.size(0), layer.hidden_size))\n",
    "                            else:\n",
    "                                h_prev, c_prev = prev\n",
    "                            h, c = layer(current, (h_prev, c_prev))\n",
    "                            current = h\n",
    "                            next_states.append((h, c))\n",
    "                        else:\n",
    "                            if prev is None:\n",
    "                                h_prev = current.new_zeros((current.size(0), layer.hidden_size))\n",
    "                            else:\n",
    "                                h_prev = prev\n",
    "                            h = layer(current, h_prev)\n",
    "                            current = h\n",
    "                            next_states.append(h)\n",
    "                        cell_ptr += 1\n",
    "                    else:\n",
    "                        current = layer(current)\n",
    "                return current, next_states if self._cells else None\n",
    "\n",
    "            def forward(self, x: torch.Tensor, state: Optional[List[Any]] = None, h: Optional[List[Any]] = None):\n",
    "                if h is not None:\n",
    "                    if state is not None:\n",
    "                        raise ValueError(\"Use either 'state' or 'h' to pass hidden state, not both.\")\n",
    "                    state = h\n",
    "\n",
    "                if not self._cells:\n",
    "                    if x.dim() == 1:\n",
    "                        return self.model(x.unsqueeze(0)).squeeze(0)\n",
    "                    if x.dim() == 2:\n",
    "                        return self.model(x)\n",
    "                    if x.dim() == 3:\n",
    "                        b, t, f = x.shape\n",
    "                        y = self.model(x.reshape(b * t, f))\n",
    "                        return y.reshape(b, t, -1)\n",
    "                    raise ValueError(\"MLP forward expects tensors with rank 1, 2, or 3.\")\n",
    "\n",
    "                if x.dim() == 1:\n",
    "                    out, _ = self.step(x.unsqueeze(0), state)\n",
    "                    return out.squeeze(0)\n",
    "\n",
    "                if x.dim() == 2:\n",
    "                    state_in = state\n",
    "                    outputs: List[torch.Tensor] = []\n",
    "                    for t in range(x.size(0)):\n",
    "                        step_input = x[t].unsqueeze(0)\n",
    "                        out, state_in = self.step(step_input, state_in)\n",
    "                        outputs.append(out)\n",
    "                    return torch.cat(outputs, dim=0)\n",
    "\n",
    "                if x.dim() == 3:\n",
    "                    state_in = state\n",
    "                    outputs: List[torch.Tensor] = []\n",
    "                    for t in range(x.size(1)):\n",
    "                        step_input = x[:, t, :]\n",
    "                        out, state_in = self.step(step_input, state_in)\n",
    "                        outputs.append(out.unsqueeze(1))\n",
    "                    return torch.cat(outputs, dim=1)\n",
    "\n",
    "                raise ValueError(\"RNN forward expects tensors with rank 1, 2, or 3.\")\n",
    "        \"\"\"\n",
    "    ).strip()\n",
    "    return class_name, code\n",
    "\n",
    "\n",
    "def save_model_code(code: str, out_name: str) -> Path:\n",
    "    \"\"\"Write generated code under ENVDIR and return the file path.\"\"\"\n",
    "    ENVDIR.mkdir(parents=True, exist_ok=True)\n",
    "    py_path = ENVDIR / f\"{out_name}.py\"\n",
    "    py_path.write_text(code, encoding='utf-8')\n",
    "    return py_path\n",
    "\n",
    "\n",
    "def import_or_reload_generated(py_path: Path, class_name: str):\n",
    "    module_name = py_path.stem\n",
    "    importlib.invalidate_caches()\n",
    "    if module_name in sys.modules:\n",
    "        module = importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        spec = importlib.util.spec_from_file_location(module_name, str(py_path))\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        assert spec.loader is not None\n",
    "        spec.loader.exec_module(module)\n",
    "        sys.modules[module_name] = module\n",
    "    return getattr(module, class_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42671e",
   "metadata": {},
   "source": [
    "---\n",
    "## LTspice data extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helping Function to extract observation data from LTSpice\n",
    "def extract_data(df, clk_col='V(ctrlclk)', threshold=0.5):\n",
    "    clk = df[clk_col].values\n",
    "\n",
    "    # Check if the clock starts at high level\n",
    "    if clk[0] > threshold:\n",
    "        raise ValueError(\"Clock started with Level Hi\")\n",
    "\n",
    "    indices = []\n",
    "    state = 'LOW'\n",
    "\n",
    "    for i in range(1, len(clk)):\n",
    "        if state == 'LOW' and clk[i - 1] <= threshold and clk[i] > threshold:\n",
    "            state = 'HIGH'  # Rising edge detected\n",
    "        elif state == 'HIGH' and clk[i - 1] > threshold and clk[i] <= threshold:\n",
    "            # Falling edge detected\n",
    "            indices.append(i)\n",
    "            state = 'LOW'\n",
    "    df_falling_edges = df.iloc[indices].reset_index(drop=True)\n",
    "    return df_falling_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23ca84",
   "metadata": {},
   "source": [
    "---\n",
    "## Step0) Global variables for Step1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b1d5e",
   "metadata": {},
   "source": [
    "---\n",
    "## Step1) Create Python code and LTspice sub-circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f55f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1() -> nn.modules:\n",
    "    # Select input sequential model\n",
    "    seq = make_model(MODEL_NAME)\n",
    "\n",
    "    # Generate & Save python code\n",
    "    class_name, code = generate_model_code_from_sequential(MODEL_NAME, seq)\n",
    "    py_path = save_model_code(code, PY_FILENAME)\n",
    "\n",
    "    # Import and instantiate the generated class\n",
    "    GenClass = import_or_reload_generated(py_path, class_name)\n",
    "    actor  = GenClass().to(DEVICE)\n",
    "\n",
    "    # Export LTSpice sub-circuit\n",
    "    export_model_to_ltspice(actor.model, filename=f\"{OUTDIR}/{SP_FILENAME}.sp\", subckt_name=SUBCKT_NAME, verbose=False)\n",
    "\n",
    "    return actor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467d605",
   "metadata": {},
   "source": [
    "## Step2) Run Simulation on LTspice and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f47b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2(module):\n",
    "    # 0) Create parameter file\n",
    "    with open(f\"{ENVDIR}/{ENV_NAME}_param.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(f\".param STEPS={SIM_STEP}\\n\")\n",
    "        nn_inputs = ' '.join(f'NNin{i+1}' for i in range(ENV_CONFIG[ENV_NAME][\"in\"]))\n",
    "        nn_outputs = ' '.join(f'NNout{i+1}' for i in range(ENV_CONFIG[ENV_NAME][\"out\"]))\n",
    "        CELL_TYPES = (nn.RNNCell, nn.GRUCell, nn.LSTMCell)\n",
    "        ports = \" \".join(p for p in [nn_inputs, (\"ctrlclk\" if MODEL_CONFIG[MODEL_NAME][\"clk_needed\"] else \"\"), nn_outputs] if p)\n",
    "        f.write(f\"X99 {ports} {SUBCKT_NAME}\\n\")\n",
    "        f.write(f\".include {SP_FILENAME}.sp\\n\")\n",
    "\n",
    "    # 1) Create PyLTspice SimRunner instance at WORKDIR\n",
    "    shutil.copy2(f\"{OUTDIR}/{SP_FILENAME}.sp\", f\"{WORKDIR}/\")  \n",
    "    shutil.copy2(f\"{ENVDIR}/{ENV_NAME}_param.txt\", f\"{WORKDIR}/\")  \n",
    "    runner = SimRunner(output_folder=WORKDIR, simulator=LTspice)\n",
    "    netlist = runner.create_netlist(f\"{ENVDIR}/{ENV_NAME}.asc\")\n",
    "        \n",
    "    # 2) Run LTSpice simulation\n",
    "    raw, log = runner.run_now(netlist, timeout=SIM_TIMEOUT)\n",
    "    raw_data = RawRead(raw)\n",
    "    df = raw_data.to_dataframe()\n",
    "    df = extract_data(df)\n",
    "\n",
    "    # 3) Extract states, actions\n",
    "    states  = df[[f'V(nnin{i+1})' for i in range(ENV_CONFIG[ENV_NAME][\"in\"])]].values[:-1]          # S[t]\n",
    "    actions  = df[[f'V(nnout{i+1})' for i in range(ENV_CONFIG[ENV_NAME][\"out\"])]].values[:-1]       # A[t]\n",
    "\n",
    "    # 4) Clean PyLTspice files\n",
    "    runner.cleanup_files()\n",
    "    os.remove(f\"{ENVDIR}/{ENV_NAME}.net\")\n",
    "    os.remove(f\"{WORKDIR}/{SP_FILENAME}.sp\")\n",
    "    os.remove(f\"{WORKDIR}/{ENV_NAME}_param.txt\")\n",
    "\n",
    "    # 5) Calculate PyTorch output using observation from LTspice\n",
    "    states_t  = torch.tensor(states,  dtype=torch.float32, device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        actions_py = actor(states_t).cpu().numpy()\n",
    "        if actions_py.ndim == 1:\n",
    "            actions_py = actions_py.reshape(-1, ENV_CONFIG[ENV_NAME][\"out\"])\n",
    "\n",
    "    return actions, actions_py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1262c",
   "metadata": {},
   "source": [
    "## Step3) Compare outputs from PyTorch and LTspice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244756d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3(actions, actions_py):\n",
    "    #Plot Scatter graph\n",
    "    fig = go.Figure()\n",
    "    ltspice_y = np.asarray(actions)\n",
    "    pytorch_y = np.asarray(actions_py)\n",
    "    samples = ltspice_y.shape[0]\n",
    "    x_axis = np.arange(samples)\n",
    "    for idx in range(ltspice_y.shape[1]):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_axis,\n",
    "            y=ltspice_y[:, idx],\n",
    "            mode='markers',\n",
    "            name=f'NNOUT{idx + 1}(LTspice)'\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_axis,\n",
    "            y=pytorch_y[:, idx],\n",
    "            mode='markers',\n",
    "            name=f'NNOUT{idx + 1}(PyTorch)'\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        title=f\"ENV={ENV_NAME}<br>MODEL={MODEL_NAME}\",\n",
    "        xaxis_title='Sample index',\n",
    "        yaxis_title='Output'\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    #Print MAE/MSE \n",
    "    diff = actions - actions_py\n",
    "    mae_per_output = np.mean(np.abs(diff), axis=0)\n",
    "    mse_per_output = np.mean(diff ** 2, axis=0)\n",
    "    for idx, (mae_val, mse_val) in enumerate(zip(mae_per_output, mse_per_output), start=1):\n",
    "        print(f\"  NNOUT{idx}: MAE={mae_val:.6f}, MSE={mse_val:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698651",
   "metadata": {},
   "source": [
    "---\n",
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x2\"\n",
    "MODEL_NAME = \"mlp\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bac0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x2\"\n",
    "MODEL_NAME = \"rnn_linear\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1726bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x2\"\n",
    "MODEL_NAME = \"gru_linear\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445acfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x2\"\n",
    "MODEL_NAME = \"linear_lstm_linear\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1777840",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x1\"\n",
    "MODEL_NAME = \"mlp\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x1\"\n",
    "MODEL_NAME = \"rnn_linear\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x1\"\n",
    "MODEL_NAME = \"gru_linear\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"env_buck_9x1\"\n",
    "MODEL_NAME = \"linear_lstm_linear\"\n",
    "PY_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output python file name\n",
    "SP_FILENAME = ENV_NAME + '_' + MODEL_NAME     # output ltspice subcircuit name\n",
    "actor = step1()\n",
    "actions, actions_py = step2(actor)\n",
    "step3(actions, actions_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be7f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
